{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run this to check if there is any GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1080 Ti'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from skimage import io, transform\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following paths are for storing data\n",
    "_NOTE: Just unzip all the [zip files](./README.md) from the ./ directory, you get the exact file structure shown below_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = './GTSRB/Final_Training/Images/'\n",
    "TEST_DIR = './GTSRB/Final_Test/Images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv(glob('%s/GT-final_test.csv'%TEST_DIR)[0], sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset  (need to be adapted depending on dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch 运作模式, 它主要需要三个模块, DataLoader, Network 和 Optimizer, 最终我们需要输出的是Network(包括其结构以及参数)\n",
    "\n",
    "![](./torch.001.jpeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Data Loader需要一个Dataset对象, 这个对象主要是要实现`__getitem__`函数, 调用这个函数主要是得到一个数据的记录, 这里我选择返回一个字典, 格式是`sample = {'image':  图像输入, 'label': 数据的标签}`, 查看`__init__`你会发现这边图像来自于一个目录, 但是其实你可以修改这种来源为任意形式, 只要能够服务`__getitem__`, 让它能正常返回数据就行."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class TrafficSignDataset(Dataset):\n",
    "    \"\"\"Traffic Signs Dataset\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        \n",
    "        if 'Train' in root_dir:\n",
    "            folders = glob('%s/*'%root_dir)\n",
    "            \n",
    "            files = [glob(os.path.join(f, '*.ppm')) for f in folders]\n",
    "            samp_num = [len(f) for f in files]\n",
    "            \n",
    "            max_num = max(samp_num)\n",
    "            \n",
    "            frame = pd.DataFrame()\n",
    "            for f, folder, num in zip(files, folders, samp_num):\n",
    "                tmp = pd.DataFrame({'Filename':f, 'ClassId': int(folder[-5:])})\n",
    "                frame = frame.append(tmp) \n",
    "                frame = frame.append(tmp.sample(max_num-num, replace=True))\n",
    "                \n",
    "            \n",
    "            self.frame = frame.sample(frac=1).reset_index(drop=True)\n",
    "            self.transform = transform\n",
    "            \n",
    "            \n",
    "        if 'Test' in root_dir:\n",
    "            self.frame = pd.read_csv('%s/GT-final_test.csv'%TEST_DIR, sep=';')[['Filename', 'ClassId']]\n",
    "            self.frame['Filename'] = self.frame['Filename'].apply(lambda x : os.path.join(root_dir, x))\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.frame.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.frame.loc[idx, 'Filename']\n",
    "        image = io.imread(img_name)\n",
    "        label = self.frame.loc[idx, 'ClassId']\n",
    "        sample = {'image': image, 'label': torch.tensor(int(label)).to('cuda')}\n",
    "\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "            \n",
    "        return sample\n",
    "    \n",
    "    \n",
    "traffic_data = TrafficSignDataset(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(5, 30, 5):\n",
    "    plt.imshow(traffic_data[i]['image'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations & Augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这边补充一些预处理, 将原始图像作一些变换, 数据格式的转换之类的, 都可以在这里发生, pytorch提供了一些内置的, 我们也可以定制, 传参就是把这些函数放到列表就会一个个执行其预处理, 注意要使用GPU的时候, 需要将张量( Tensor ) 放到GPU中, 其实就一个`.to('cuda')`就Ok了\n",
    "\n",
    "可以发现, 其实这是服务于上面定义Dataset对象时初始化的参数, `transform`的."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import RandomResizedCrop, RandomRotation, RandomAffine, ToPILImage, ToTensor, Resize, Grayscale\n",
    "\n",
    "class ToDeviceTensor(object):\n",
    "    def __call__(self, image_tensor):\n",
    "        return ToTensor()(image_tensor).to('cuda')\n",
    "    \n",
    "    \n",
    "augment_tf = [] # Addd some augmentations here\n",
    "\n",
    "# Train\n",
    "train_composed = transforms.Compose([ToPILImage()] + augment_tf + [Resize((32, 32)), ToDeviceTensor()])  \n",
    "traffic_data_train = TrafficSignDataset(ROOT_DIR, transform=train_composed)\n",
    "\n",
    "\n",
    "# Test\n",
    "test_composed = transforms.Compose([ToPILImage(), Resize((32, 32)), ToDeviceTensor()])\n",
    "traffic_data_test = TrafficSignDataset(TEST_DIR, transform=test_composed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 得到一个Dataloader, 其实就是传入一个带`__getitem__` 的对象即可, 然后定义一个`batch_size`参数, 就可以指定每次传入多少的数据了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(traffic_data_train, batch_size=16)\n",
    "testloader = DataLoader(traffic_data_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这边定义一个网络, 输出是一个未调优的`net`对象, 表示这个网络和其参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "num_classes = 43\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 16, 5) \n",
    "        self.conv2 = nn.Conv2d(16, 32, 5) \n",
    "        self.conv3 = nn.Conv2d(32, 128, 5) \n",
    "        self.conv4 = nn.Conv2d(128, 256, 3)\n",
    "        self.fc5 = nn.Linear(256*3*3, num_classes) \n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # one activated conv layer\n",
    "        x = F.relu(self.conv1(x)) # 32 -> 28\n",
    "        x = self.pool(F.relu(self.conv2(x))) # 28 -> 24 -> 12\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.conv3(x)) # 12 -> 8\n",
    "        x = self.pool(F.relu(self.conv4(x))) # 8 -> 6 -> 3\n",
    "        x = self.drop(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        # final output\n",
    "        return x\n",
    "\n",
    "# instantiate and print your Net\n",
    "net = Net().cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Trainning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义 Optimizer, 训练网络, 输出还是net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(30):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # 这边使用了DataLoader的输出\n",
    "        inputs, labels = data['image'], data['label']\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关键一行是`outputs = net(images)`, 这个image是dataloader的一个输出, 就是普通的image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(num_classes))\n",
    "class_total = list(0. for i in range(num_classes))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data['image'], data['label']\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        \n",
    "        for i in range(16):\n",
    "            try:\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "\n",
    "for i in range(43):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        i, 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum(class_correct)/sum(class_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
